from mindcv.data import create_dataset, create_transforms, create_loader
import os
import mindspore as ms
from mindspore import Model, save_checkpoint, load_checkpoint,  nn
from mindspore.train.callback import Callback
import mindspore as ms
import mindspore.nn as nn
import mindspore.ops as ops


ms.set_context(mode=ms.GRAPH_MODE, device_target="Ascend")

batch_size = 64
num_workers = 16
num_classes = 31
data_dir = "./rockdataset4"

# åŠ è½½æ•°æ®é›†
dataset_train = create_dataset(root=data_dir, split='train', num_parallel_workers=num_workers, shuffle=True)
dataset_val = create_dataset(root=data_dir, split='val', num_parallel_workers=num_workers, shuffle=True)

class_names = dataset_train.get_class_indexing()
class_names = dict(zip(class_names.values(),class_names.keys()))
print(class_names)

# æ•°æ®å¢å¼º
trans = create_transforms(is_training=True, image_resize=384,scale=(0.5, 1.0), color_jitter=(0.2, 0.2, 0.2, 0.02))
trans_val = create_transforms(is_training=False, image_resize=384)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
loader_train = create_loader(dataset=dataset_train,
                             batch_size=batch_size,
                             is_training=True,
                             num_classes=num_classes,
                             transform=trans,
                             num_parallel_workers=num_workers)

num_batches = loader_train.get_dataset_size()

# ä¿ç•™ç©ºé—´æ³¨æ„åŠ›æ¨¡å—

class SpatialAttention(nn.Cell):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel_size, pad_mode='same')
        self.sigmoid = nn.Sigmoid()
        self.reduce_mean = ops.ReduceMean(keep_dims=True)  # è®¡ç®—é€šé“å‡å€¼
        self.reduce_max = ops.ReduceMax(keep_dims=True)  # è®¡ç®—é€šé“æœ€å¤§å€¼

    def construct(self, x):
        avg_out = self.reduce_mean(x, 1)  # è®¡ç®—é€šé“å‡å€¼
        max_out = self.reduce_max(x, 1)   # è®¡ç®—é€šé“æœ€å¤§å€¼
        x = ops.Concat(1)((avg_out, max_out))  # æ‹¼æ¥åé€šé“æ•°å˜ä¸º 2
        x = self.conv1(x)  # é€šè¿‡ 7x7 å·ç§¯å±‚
        return self.sigmoid(x)  # ç»´åº¦ä»ç„¶æ˜¯ (batch, 1, H, W)

class CBAM(nn.Cell):
    def __init__(self, kernel_size=7):
        super(CBAM, self).__init__()
        self.sa = SpatialAttention(kernel_size)

    def construct(self, x):
        x = x * self.sa(x)  # ä»…åº”ç”¨ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
        return x

# åˆ›å»ºæ¨¡å‹å¹¶æ·»åŠ  CBAM
from mindcv.models import create_model

class CBAMEfficientNet(nn.Cell):
    def __init__(self, base_model, num_classes, apply_softmax=False):
        super(CBAMEfficientNet, self).__init__()
        self.features = base_model.features  # EfficientNet çš„ç‰¹å¾æå–éƒ¨åˆ†
        self.cbam = CBAM(kernel_size=7)  # ä»…ä½¿ç”¨ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
        self.reduce_mean = ops.ReduceMean(keep_dims=True)  # è®¡ç®—å…¨å±€å‡å€¼
        self.flatten = nn.Flatten()  # å±•å¹³
        
        # ä½¿ç”¨ mlp_head ä½œä¸ºåˆ†ç±»å±‚
        self.classifier = base_model.mlp_head  
        self.apply_softmax = apply_softmax  # æ§åˆ¶æ˜¯å¦åº”ç”¨ Softmax

    def construct(self, x):
        x = self.features(x)  # EfficientNet æå–ç‰¹å¾ï¼Œè¾“å‡º (batch, 1280, H, W)
        x = self.cbam(x)  # ä»…åº”ç”¨ç©ºé—´æ³¨æ„åŠ›
        x = self.reduce_mean(x, (2, 3))  # è®¡ç®—å…¨å±€å‡å€¼ï¼Œå˜ä¸º (batch, 1280, 1, 1)
        x = self.flatten(x)  # å˜ä¸º (batch, 1280)
        x = self.classifier(x)  # é€å…¥åˆ†ç±»å±‚

        if self.apply_softmax:
            x = ops.Squeeze()(x)
            x = ops.Softmax()(x)  # è®¡ç®—æ¦‚ç‡
        return x



# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
base_model = create_model(model_name='efficientnet_b1', num_classes=num_classes, pretrained=True)
network = CBAMEfficientNet(base_model, num_classes)

#ms.amp.auto_mixed_precision(network, amp_level="O2")  # "O2" æ˜¯æ¨èçº§åˆ«

# åˆ›å»ºæŸå¤±å‡½æ•°
from mindcv.loss import create_loss
loss = create_loss(name='CE')

# è®¾ç½®å­¦ä¹ ç‡ç­–ç•¥
from mindcv.scheduler import create_scheduler
lr_scheduler = create_scheduler(
    steps_per_epoch=num_batches,
    scheduler='constant',
    lr=0.001,
    min_lr=1e-6,
    warmup_epochs=5,
)

# è®¾ç½®ä¼˜åŒ–å™¨
from mindcv.optim import create_optimizer
opt = create_optimizer(network.trainable_params(), opt='adam', lr=lr_scheduler)

# å°è£…å¯è®­ç»ƒæˆ–æ¨ç†çš„å®ä¾‹
model = Model(network, loss_fn=loss, optimizer=opt, metrics={'accuracy'})

# å®šä¹‰ä¿å­˜è·¯å¾„
ckpt_save_dir = './ckpt'
if not os.path.exists(ckpt_save_dir):
    os.makedirs(ckpt_save_dir)

# è®­ç»ƒå›è°ƒ
class BestCheckpointCallback(Callback):
    def __init__(self, model, eval_loader, save_path, eval_interval=1):
        super(BestCheckpointCallback, self).__init__()
        self.model = model
        self.eval_loader = eval_loader
        self.save_path = save_path
        self.best_acc = 0.0
        self.best_epoch = 0
        self.eval_interval = eval_interval

    def on_train_epoch_end(self, run_context):
        cb_params = run_context.original_args()
        epoch = cb_params.cur_epoch_num
        
        if epoch % self.eval_interval == 0:
            acc = self.model.eval(self.eval_loader, dataset_sink_mode=False)
            acc_value = acc.get("accuracy", 0.0)
            print(f"Epoch {epoch}: éªŒè¯é›†å‡†ç¡®ç‡ = {acc_value:.4f}")
            
            if acc_value > self.best_acc:
                self.best_acc = acc_value
                self.best_epoch = epoch
                best_ckpt_path = os.path.join(self.save_path, "best_checkpoint.ckpt")
                save_checkpoint(self.model._network, best_ckpt_path)
                print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼Epoch {epoch}, æœ€é«˜å‡†ç¡®ç‡: {self.best_acc:.4f}")

# åˆ›å»ºéªŒè¯é›†æ•°æ®åŠ è½½å™¨
loader_val = create_loader(dataset=dataset_val,
                           batch_size=batch_size,
                           is_training=False,
                           num_classes=num_classes,
                           transform=trans_val,
                           num_parallel_workers=num_workers)

best_ckpt_cb = BestCheckpointCallback(model, loader_val, ckpt_save_dir)

from mindspore import LossMonitor, TimeMonitor

best_ckpt_cb = BestCheckpointCallback(model, loader_val, ckpt_save_dir)

summary_collector = ms.SummaryCollector(summary_dir='./summary_dir/summary_02')

model.train(100, loader_train, callbacks=[LossMonitor(num_batches//5), TimeMonitor(num_batches//5), best_ckpt_cb, summary_collector], dataset_sink_mode=False)

# è¯„ä¼°æœ€ä½³æ¨¡å‹
best_ckpt_path = os.path.join(ckpt_save_dir, "best_checkpoint.ckpt")
load_checkpoint(best_ckpt_path, net=network)

final_acc = model.eval(loader_val, dataset_sink_mode=False)
print("ğŸ¯ æœ€ç»ˆæœ€ä½³æ¨¡å‹çš„éªŒè¯é›†å‡†ç¡®ç‡:", final_acc)